{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 15:40:02.995758: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN w/ word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Removes URLs that start with http\n",
    "    text = re.sub(r'www\\S+', '', text)   # Removes URLs that start with www\n",
    "\n",
    "    text = text.lower()  # Lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df['processed_posts'] = df['posts'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>processed_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>[intj, moment, sportscenter, top, ten, play, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>[finding, lack, post, boring, position, often,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>[one, course, say, know, blessing, absolutely,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>[intp, enjoyed, conversation, day, esoteric, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>[another, silly, misconception, approaching, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>[always, think, cat, fi, doms, reason, website...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>[thread, already, exists, someplace, else, hec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>[many, question, thing, would, take, purple, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>[conflicted, right, come, wanting, child, hone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>[long, since, personalitycafe, although, seem,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "...    ...                                                ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...   \n",
       "8672  INTP  'So many questions when i do these things.  I ...   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...   \n",
       "8674  INFP  'It has been too long since I have been on per...   \n",
       "\n",
       "                                        processed_posts  \n",
       "0     [intj, moment, sportscenter, top, ten, play, e...  \n",
       "1     [finding, lack, post, boring, position, often,...  \n",
       "2     [one, course, say, know, blessing, absolutely,...  \n",
       "3     [intp, enjoyed, conversation, day, esoteric, g...  \n",
       "4     [another, silly, misconception, approaching, l...  \n",
       "...                                                 ...  \n",
       "8670  [always, think, cat, fi, doms, reason, website...  \n",
       "8671  [thread, already, exists, someplace, else, hec...  \n",
       "8672  [many, question, thing, would, take, purple, p...  \n",
       "8673  [conflicted, right, come, wanting, child, hone...  \n",
       "8674  [long, since, personalitycafe, although, seem,...  \n",
       "\n",
       "[8675 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>processed_posts</th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>F/T</th>\n",
       "      <th>P/J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>[intj, moment, sportscenter, top, ten, play, e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>[finding, lack, post, boring, position, often,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>[one, course, say, know, blessing, absolutely,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>[intp, enjoyed, conversation, day, esoteric, g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>[another, silly, misconception, approaching, l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>[always, think, cat, fi, doms, reason, website...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>[thread, already, exists, someplace, else, hec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>[many, question, thing, would, take, purple, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>[conflicted, right, come, wanting, child, hone...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>[long, since, personalitycafe, although, seem,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "...    ...                                                ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...   \n",
       "8672  INTP  'So many questions when i do these things.  I ...   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...   \n",
       "8674  INFP  'It has been too long since I have been on per...   \n",
       "\n",
       "                                        processed_posts  I/E  N/S  F/T  P/J  \n",
       "0     [intj, moment, sportscenter, top, ten, play, e...    0    0    0    1  \n",
       "1     [finding, lack, post, boring, position, often,...    1    0    1    0  \n",
       "2     [one, course, say, know, blessing, absolutely,...    0    0    1    0  \n",
       "3     [intp, enjoyed, conversation, day, esoteric, g...    0    0    1    1  \n",
       "4     [another, silly, misconception, approaching, l...    1    0    1    1  \n",
       "...                                                 ...  ...  ...  ...  ...  \n",
       "8670  [always, think, cat, fi, doms, reason, website...    0    1    0    0  \n",
       "8671  [thread, already, exists, someplace, else, hec...    1    0    0    0  \n",
       "8672  [many, question, thing, would, take, purple, p...    0    0    1    0  \n",
       "8673  [conflicted, right, come, wanting, child, hone...    0    0    0    0  \n",
       "8674  [long, since, personalitycafe, although, seem,...    0    0    0    0  \n",
       "\n",
       "[8675 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we create 4 new columns each containing information about one of the key dichotomies of MBTI\n",
    "\"\"\"\n",
    "\n",
    "def label_mbti_ie(row):\n",
    "    if \"I\" in row['type']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def label_mbti_ns(row):\n",
    "    if \"N\" in row['type']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def label_mbti_ft(row):\n",
    "    if \"F\" in row['type']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def label_mbti_pj(row):\n",
    "    if \"P\" in row['type']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['I/E'] = df.apply(label_mbti_ie, axis=1)\n",
    "df['N/S'] = df.apply(label_mbti_ns, axis=1)\n",
    "df['F/T'] = df.apply(label_mbti_ft, axis=1)\n",
    "df['P/J'] = df.apply(label_mbti_pj, axis=1)\n",
    "\n",
    "# df['I-E'] = df['Type'].apply(lambda x: 1 if 'E' in x['type'] else 0)\n",
    "# df['N-S'] = df['Type'].apply(lambda x: 1 if 'S' in x['type'] else 0)\n",
    "# df['F-T'] = df['Type'].apply(lambda x: 1 if 'T' in x['type'] else 0)\n",
    "# df['P-J'] = df['Type'].apply(lambda x: 1 if 'J' in x['type'] else 0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google News Word2Vec Model\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Embedding, Input\n",
    "\n",
    "\n",
    "\n",
    "# Load the Google News Word2Vec model\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_word2vec_matrices(data, model, max_length=800):\n",
    "    \"\"\"Convert sentences to a matrix of word vectors.\"\"\"\n",
    "    vector_size = model.vector_size\n",
    "    embeddings = np.zeros((len(data), max_length, vector_size))\n",
    "    \n",
    "    for i, sentence in enumerate(data):\n",
    "        words = sentence[:max_length]\n",
    "        for j, word in enumerate(words):\n",
    "            if word in model:\n",
    "                embeddings[i, j, :] = model[word]\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google word2vec 4 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare input data\n",
    "X = get_google_word2vec_matrices(df['processed_posts'], word2vec_model)\n",
    "Y = df[['I/E', 'N/S', 'F/T', 'P/J']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>F/T</th>\n",
       "      <th>P/J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I/E  N/S  F/T  P/J\n",
       "0    0    0    0    1\n",
       "1    1    0    1    0\n",
       "2    0    0    1    0\n",
       "3    0    0    1    1\n",
       "4    1    0    1    1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8675, 800, 300), (8675, 4))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.16308594,  0.02709961,  0.14453125, ...,  0.31445312,\n",
       "          0.07861328, -0.03564453],\n",
       "        [-0.0625    ,  0.04125977,  0.06030273, ..., -0.04882812,\n",
       "         -0.10009766,  0.02246094],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.01611328,  0.03173828, -0.21386719, ...,  0.1171875 ,\n",
       "          0.13574219,  0.11425781],\n",
       "        [ 0.08154297, -0.03149414, -0.2578125 , ..., -0.03295898,\n",
       "         -0.04248047,  0.01098633],\n",
       "        [-0.02148438, -0.00379944, -0.11474609, ..., -0.29882812,\n",
       "         -0.13574219,  0.03613281],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.0456543 , -0.14550781,  0.15625   , ..., -0.01586914,\n",
       "          0.00671387, -0.00188446],\n",
       "        [ 0.03063965,  0.07080078,  0.07226562, ..., -0.0098877 ,\n",
       "         -0.02453613,  0.01397705],\n",
       "        [-0.03613281, -0.12109375,  0.13378906, ..., -0.08642578,\n",
       "          0.14355469,  0.02734375],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.19335938, -0.0043335 , -0.03222656, ...,  0.05200195,\n",
       "          0.02758789, -0.0065918 ],\n",
       "        [ 0.10107422,  0.09912109, -0.03759766, ..., -0.265625  ,\n",
       "         -0.0703125 ,  0.06738281],\n",
       "        [ 0.16992188,  0.04907227,  0.08154297, ..., -0.08740234,\n",
       "          0.18261719,  0.04150391],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.10595703,  0.16503906,  0.03039551, ...,  0.01757812,\n",
       "          0.203125  , -0.00147247],\n",
       "        [ 0.14550781, -0.0189209 ,  0.09619141, ..., -0.04492188,\n",
       "         -0.05395508,  0.0300293 ],\n",
       "        [ 0.02185059,  0.06079102,  0.04541016, ..., -0.10791016,\n",
       "          0.16699219, -0.16992188],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.14355469,  0.10449219, -0.19042969, ...,  0.20507812,\n",
       "         -0.00148773, -0.06396484],\n",
       "        [-0.00643921,  0.03198242,  0.01287842, ..., -0.0456543 ,\n",
       "         -0.00250244, -0.06201172],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "# Create a single label that represents all combinations\n",
    "# Y['combined'] = Y.apply(lambda row: ''.join(row.values.astype(str)), axis=1)\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y['combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/word2vec/train/X_train.npy', X_train)\n",
    "np.save('../data/word2vec/train/Y_train.npy', Y_train)\n",
    "np.save('../data/word2vec/test/X_val.npy', X_val)\n",
    "np.save('../data/word2vec/test/Y_val.npy', Y_val)\n",
    "\n",
    "# np.save('../data/word2vec/train/X_train_balance.npy', X_train)\n",
    "# np.save('../data/word2vec/train/Y_train_balance.npy', Y_train)\n",
    "# np.save('../data/word2vec/test/X_val_balance.npy', X_val)\n",
    "# np.save('../data/word2vec/test/Y_val_balance.npy', Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../data/word2vec/train/X_train.npy')\n",
    "Y_train = np.load('../data/word2vec/train/Y_train.npy')\n",
    "X_val = np.load('../data/word2vec/test/X_val.npy')\n",
    "Y_val = np.load('../data/word2vec/test/Y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 16:51:58.435181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, GlobalMaxPooling1D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_mbti\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 800, 300)]   0           []                               \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 1024)         52171328    ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " output1 (Sequential)           (None, 1)            131329      ['sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " output2 (Sequential)           (None, 1)            131329      ['sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " output3 (Sequential)           (None, 1)            131329      ['sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " output4 (Sequential)           (None, 1)            131329      ['sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 52,696,644\n",
      "Trainable params: 52,696,516\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  # max_length and vector_size\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "shared_layers = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=7, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    # Conv1D(filters=32, kernel_size=7, activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    # Conv1D(filters=16, kernel_size=7, activation='relu'),\n",
    "    # BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu')\n",
    "])\n",
    "\n",
    "shared_output = shared_layers(inputs)\n",
    "\n",
    "output1_layers = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2), \n",
    "    # Dense(8, activation='relu'),\n",
    "    # Dropout(0.2), \n",
    "    Dense(1, activation='sigmoid'),\n",
    "], name='output1')\n",
    "\n",
    "output2_layers = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2), \n",
    "    # Dense(8, activation='relu'),\n",
    "    # Dropout(0.2), \n",
    "    Dense(1, activation='sigmoid'),\n",
    "], name='output2')\n",
    "\n",
    "output3_layers = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5), \n",
    "    # Dense(8, activation='relu'),\n",
    "    # Dropout(0.4), \n",
    "    Dense(1, activation='sigmoid'),\n",
    "], name='output3')\n",
    "\n",
    "output4_layers = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5), \n",
    "    # Dense(8, activation='relu'),\n",
    "    # Dropout(0.3),  \n",
    "    Dense(1, activation='sigmoid'),\n",
    "], name='output4')\n",
    "\n",
    "# Connect each sequential output to the shared output\n",
    "output1 = output1_layers(shared_output)\n",
    "output2 = output2_layers(shared_output)\n",
    "output3 = output3_layers(shared_output)\n",
    "output4 = output4_layers(shared_output)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "# Assemble and compile the model\n",
    "cnn_4_out_model = Model(inputs=inputs, outputs=[output1, output2, output3, output4], name='cnn_mbti')\n",
    "cnn_4_out_model.compile(optimizer=optimizer,\n",
    "              loss={'output1': 'binary_crossentropy', 'output2': 'binary_crossentropy',\n",
    "                    'output3': 'binary_crossentropy', 'output4': 'binary_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy', 'output3': 'accuracy', 'output4': 'accuracy'})\n",
    "\n",
    "cnn_4_out_model.summary()\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "#early_stopping_monitor = EarlyStopping(monitor='output1_accuracy', patience=2, verbose=2, mode='min', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6940, 800, 300), (6940, 4))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train, y2_train, y3_train, y4_train = Y_train[:, 0], Y_train[:,1], Y_train[:,2], Y_train[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "109/109 - 73s - loss: 3.1076 - output1_loss: 0.7296 - output2_loss: 0.5671 - output3_loss: 0.9327 - output4_loss: 0.8781 - output1_accuracy: 0.7490 - output2_accuracy: 0.8500 - output3_accuracy: 0.5690 - output4_accuracy: 0.5733 - 73s/epoch - 670ms/step\n",
      "Epoch 2/3\n",
      "109/109 - 70s - loss: 1.5399 - output1_loss: 0.3457 - output2_loss: 0.2327 - output3_loss: 0.4556 - output4_loss: 0.5059 - output1_accuracy: 0.8354 - output2_accuracy: 0.8987 - output3_accuracy: 0.7888 - output4_accuracy: 0.7585 - 70s/epoch - 641ms/step\n",
      "Epoch 3/3\n",
      "109/109 - 74s - loss: 0.4713 - output1_loss: 0.1066 - output2_loss: 0.0548 - output3_loss: 0.1357 - output4_loss: 0.1743 - output1_accuracy: 0.9611 - output2_accuracy: 0.9814 - output3_accuracy: 0.9491 - output4_accuracy: 0.9347 - 74s/epoch - 677ms/step\n",
      "55/55 - 8s - loss: 2.3732 - output1_loss: 0.5751 - output2_loss: 0.4469 - output3_loss: 0.6401 - output4_loss: 0.7110 - output1_accuracy: 0.7343 - output2_accuracy: 0.8548 - output3_accuracy: 0.6161 - output4_accuracy: 0.5251 - 8s/epoch - 152ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 3\n",
    "train_metrics = cnn_4_out_model.fit(x=X_train, y={'output1': y1_train, 'output2': y2_train, \n",
    "                        'output3': y3_train, 'output4': y4_train}, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    verbose=2\n",
    "                    )\n",
    "\n",
    "results = cnn_4_out_model.evaluate(x=X_val, \n",
    "                        y={'output1': Y_val[:,0], 'output2': Y_val[:,1], \n",
    "                        'output3': Y_val[:,2], 'output4': Y_val[:,3]}, \n",
    "                        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract accuracy from each output\n",
    "acc_output1 = train_metrics.history['output1_accuracy']\n",
    "acc_output2 = train_metrics.history['output2_accuracy']\n",
    "acc_output3 = train_metrics.history['output3_accuracy']\n",
    "acc_output4 = train_metrics.history['output4_accuracy']\n",
    "\n",
    "# Calculate the average accuracy over all outputs per epoch\n",
    "average_accuracy_per_epoch = [np.mean(values) for values in zip(acc_output1, acc_output2, acc_output3, acc_output4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7342939376831055, 0.8547550439834595, 0.6161383390426636, 0.5250720381736755)\n",
      "Average Accuracy: 0.682564839720726\n"
     ]
    }
   ],
   "source": [
    "loss_total = results[0]\n",
    "loss_output1, acc_output1 = results[1], results[5]\n",
    "loss_output2, acc_output2 = results[2], results[6]\n",
    "loss_output3, acc_output3 = results[3], results[7]\n",
    "loss_output4, acc_output4 = results[4], results[8]\n",
    "average_accuracy = (acc_output1 + acc_output2 + acc_output3 + acc_output4) / 4\n",
    "print((acc_output1, acc_output2, acc_output3, acc_output4))\n",
    "print(f'Average Accuracy: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 7s 127ms/step\n"
     ]
    }
   ],
   "source": [
    "y1_predict, y2_predict, y3_predict, y4_predict = cnn_4_out_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1735, 1), (1735, 1), (1735, 1), (1735, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_predict.shape, y2_predict.shape, y3_predict.shape, y4_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "    # Check if all four predicted classes match the true classes\n",
    "    correct_predictions = np.all(y_true == y_pred, axis=1)\n",
    "    accuracy = np.mean(correct_predictions)\n",
    "    return accuracy\n",
    "\n",
    "def threshold_prediction(value, threshold):\n",
    "    if value >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "threshold = 0.5\n",
    "y1_predict_thresholded = np.array([threshold_prediction(value, threshold) for value in y1_predict])\n",
    "y2_predict_thresholded = np.array([threshold_prediction(value, threshold) for value in y2_predict])\n",
    "y3_predict_thresholded = np.array([threshold_prediction(value, threshold) for value in y3_predict])\n",
    "y4_predict_thresholded = np.array([threshold_prediction(value, threshold) for value in y4_predict])\n",
    "\n",
    "y1_test_reshaped, y2_test_reshaped, y3_test_reshaped, y4_test_reshaped = Y_val[:,0].reshape(-1, 1), Y_val[:,1].reshape(-1, 1), Y_val[:,2].reshape(-1, 1), Y_val[:,3].reshape(-1, 1)\n",
    "\n",
    "y_pred_combined = np.vstack((y1_predict_thresholded,\n",
    "                                 y2_predict_thresholded,\n",
    "                                 y3_predict_thresholded,\n",
    "                                 y4_predict_thresholded)).T\n",
    "\n",
    "y_test_combined = np.vstack((y1_test_reshaped.T,\n",
    "                                y2_test_reshaped.T,\n",
    "                                y3_test_reshaped.T,\n",
    "                                y4_test_reshaped.T)).T\n",
    "\n",
    "accuracy = calculate_accuracy(y_test_combined, y_pred_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy across all four categories: 0.21210374639769453\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy across all four categories: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:53:34) [Clang 16.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95a8b902d17fe767a9a89dc40947dbbffb75fb8c37a8f89f9453213a57fd418c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
