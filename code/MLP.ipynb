{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')  # Needed for tokenizing words.\n",
    "nltk.download('stopwords')  # Needed for stop words that are used in the preprocessing.\n",
    "nltk.download('wordnet')  # Needed for lemmatization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add 4 Classifier Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/data.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8675.000000\n",
       "mean     1262.678963\n",
       "std       317.261077\n",
       "min         4.000000\n",
       "25%      1081.000000\n",
       "50%      1314.000000\n",
       "75%      1497.000000\n",
       "max      2212.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'] = df['posts'].apply(lambda x: len(x.split(' ')))\n",
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>F/T</th>\n",
       "      <th>P/J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  I/E  N/S  F/T  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...    0    0    0   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...    1    0    1   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...    0    0    1   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...    0    0    1   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...    1    0    1   \n",
       "...    ...                                                ...  ...  ...  ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...    0    1    0   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...    1    0    0   \n",
       "8672  INTP  'So many questions when i do these things.  I ...    0    0    1   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...    0    0    0   \n",
       "8674  INFP  'It has been too long since I have been on per...    0    0    0   \n",
       "\n",
       "      P/J  \n",
       "0       1  \n",
       "1       0  \n",
       "2       0  \n",
       "3       1  \n",
       "4       1  \n",
       "...   ...  \n",
       "8670    0  \n",
       "8671    0  \n",
       "8672    0  \n",
       "8673    0  \n",
       "8674    0  \n",
       "\n",
       "[8675 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we create 4 new columns each containing information about one of the key dichotomies of MBTI\n",
    "\"\"\"\n",
    "\n",
    "def label_mbti_ie(row):\n",
    "    if \"I\" in row['type']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def label_mbti_ns(row):\n",
    "    if \"N\" in row['type']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def label_mbti_ft(row):\n",
    "    if \"F\" in row['type']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def label_mbti_pj(row):\n",
    "    if \"P\" in row['type']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df['I/E'] = df.apply(label_mbti_ie, axis=1)\n",
    "df['N/S'] = df.apply(label_mbti_ns, axis=1)\n",
    "df['F/T'] = df.apply(label_mbti_ft, axis=1)\n",
    "df['P/J'] = df.apply(label_mbti_pj, axis=1)\n",
    "\n",
    "# df['I-E'] = df['Type'].apply(lambda x: 1 if 'E' in x['type'] else 0)\n",
    "# df['N-S'] = df['Type'].apply(lambda x: 1 if 'S' in x['type'] else 0)\n",
    "# df['F-T'] = df['Type'].apply(lambda x: 1 if 'T' in x['type'] else 0)\n",
    "# df['P-J'] = df['Type'].apply(lambda x: 1 if 'J' in x['type'] else 0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Removes URLs that start with http\n",
    "    text = re.sub(r'www\\S+', '', text)   # Removes URLs that start with www\n",
    "\n",
    "    text = text.lower()  # Lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "df['processed_posts'] = df['posts'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['processed_posts']\n",
    "y = df[['I/E', 'N/S', 'F/T', 'P/J']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# _, _, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "# _, _, y3_train, y3_test = train_test_split(X, y3, test_size=0.2, random_state=42)\n",
    "# _, _, y4_train, y4_test = train_test_split(X, y4, test_size=0.2, random_state=42) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6940,), (1735,), (6940, 4), (1735, 4))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF-IDF data and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kzzzz/opt/anaconda3/envs/2470project/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Train Matrix Shape: (6940, 71597)\n",
      "TF-IDF Feature Names: ['aa' 'aaa' 'aaaa' ... 'ﾉｼ' 'ﾟ' 'ﾟдﾟщ']\n",
      "TF-IDF Test Matrix Shape: (1735, 71597)\n",
      "TF-IDF Feature Names: ['aa' 'aaa' 'aaaa' ... 'ﾉｼ' 'ﾟ' 'ﾟдﾟщ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Show TF-IDF result\n",
    "print(\"TF-IDF Train Matrix Shape:\", tfidf_matrix_train.shape)\n",
    "print(\"TF-IDF Feature Names:\", tfidf_feature_names)\n",
    "\n",
    "# TF-IDF\n",
    "# tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(X_test).toarray()\n",
    "# tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Show TF-IDF result\n",
    "print(\"TF-IDF Test Matrix Shape:\", tfidf_matrix_test.shape)\n",
    "print(\"TF-IDF Feature Names:\", tfidf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['I/E'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = tfidf_matrix_train\n",
    "y1_train = y_train['I/E']\n",
    "y2_train = y_train['N/S']\n",
    "y3_train = y_train['F/T']\n",
    "y4_train = y_train['P/J']\n",
    "\n",
    "X_test = tfidf_matrix_test\n",
    "y1_test = y_test['I/E']\n",
    "y2_test = y_test['N/S']\n",
    "y3_test = y_test['F/T']\n",
    "y4_test = y_test['P/J']\n",
    "\n",
    "# X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "# _, _, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "# _, _, y3_train, y3_test = train_test_split(X, y3, test_size=0.2, random_state=42)\n",
    "# _, _, y4_train, y4_test = train_test_split(X, y4, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6940, 71597), (6940,), (6940,), (6940,), (6940,))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y1_train.shape, y2_train.shape, y3_train.shape, y4_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1735, 71597), (1735,), (1735,), (1735,), (1735,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y1_test.shape, y2_test.shape, y3_test.shape, y4_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "np.save('../data/tfidf/train/X_train.npy', X_train)\n",
    "np.save('../data/tfidf/train/y1_train.npy', y1_train)\n",
    "np.save('../data/tfidf/train/y2_train.npy', y2_train)\n",
    "np.save('../data/tfidf/train/y3_train.npy', y3_train)\n",
    "np.save('../data/tfidf/train/y4_train.npy', y4_train)\n",
    "\n",
    "np.save('../data/tfidf/test/X_test.npy', X_test)\n",
    "np.save('../data/tfidf/test/y1_test.npy', y1_test)\n",
    "np.save('../data/tfidf/test/y2_test.npy', y2_test)\n",
    "np.save('../data/tfidf/test/y3_test.npy', y3_test)\n",
    "np.save('../data/tfidf/test/y4_test.npy', y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "X_train = np.load('../data/tfidf/train/X_train.npy')\n",
    "y1_train = np.load('../data/tfidf/train/y1_train.npy')\n",
    "y2_train = np.load('../data/tfidf/train/y2_train.npy')\n",
    "y3_train = np.load('../data/tfidf/train/y3_train.npy')\n",
    "y4_train = np.load('../data/tfidf/train/y4_train.npy')\n",
    "\n",
    "X_test = np.load('../data/tfidf/test/X_test.npy')\n",
    "y1_test = np.load('../data/tfidf/test/y1_test.npy')\n",
    "y2_test = np.load('../data/tfidf/test/y2_test.npy')\n",
    "y3_test = np.load('../data/tfidf/test/y3_test.npy')\n",
    "y4_test = np.load('../data/tfidf/test/y4_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = (X_train, y1_train, y2_train, y3_train, y4_train)\n",
    "test_inputs = (X_test, y1_test, y2_test, y3_test, y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6940, 71597), (6940,), (6940,), (6940,), (6940,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y1_train.shape, y2_train.shape, y3_train.shape, y4_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1735, 71597), (1735,), (1735,), (1735,), (1735,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y1_test.shape, y2_test.shape, y3_test.shape, y4_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382, 246, 798, 669)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y1_test), sum(y2_test), sum(y3_test), sum(y4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kzzzz/Desktop/24Spring/Deep Learning/Project/Detecting_Your_MBTI_Using_NLP/code\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "# X_loaded = np.load('../data/tfidf/X.npy')\n",
    "# y1_loaded = np.load('../data/tfidf/y1.npy')\n",
    "# y2_loaded = np.load('../data/tfidf/y2.npy')\n",
    "# y3_loaded = np.load('../data/tfidf/y3.npy')\n",
    "# y4_loaded = np.load('../data/tfidf/y4.npy')\n",
    "\n",
    "# X_train, X_test, y1_train, y1_test = train_test_split(X_loaded, y1_loaded, test_size=0.2, random_state=42)\n",
    "# _, _, y2_train, y2_test = train_test_split(X_loaded, y2_loaded, test_size=0.2, random_state=42)\n",
    "# _, _, y3_train, y3_test = train_test_split(X_loaded, y3_loaded, test_size=0.2, random_state=42)\n",
    "# _, _, y4_train, y4_test = train_test_split(X_loaded, y4_loaded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 16:08:15.815951: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Conv1D, GlobalMaxPooling1D, Dropout, Reshape, Flatten\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "shared_layers = Sequential([\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(256, activation='relu')\n",
    "])\n",
    "# shared_layers = Sequential([\n",
    "#     Reshape((X.shape[0], X.shape[1], 1)),\n",
    "#     Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=input_shape),\n",
    "#     GlobalMaxPooling1D(),\n",
    "#     Dropout(0.5)\n",
    "# ])\n",
    "shared_output = shared_layers(inputs)\n",
    "\n",
    "output1_layers = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name='output1')\n",
    "\n",
    "output2_layers = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name='output2')\n",
    "\n",
    "output3_layers = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name='output3')\n",
    "\n",
    "output4_layers = Sequential([\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "], name='output4')\n",
    "\n",
    "# Connect each sequential output to the shared output\n",
    "output1 = output1_layers(shared_output)\n",
    "output2 = output2_layers(shared_output)\n",
    "output3 = output3_layers(shared_output)\n",
    "output4 = output4_layers(shared_output)\n",
    "\n",
    "mlp_model = Model(inputs=inputs, outputs=[output1, output2, output3, output4], name='mlp_model')\n",
    "mlp_model.compile(optimizer='adam',\n",
    "              loss={'output1': 'binary_crossentropy', 'output2': 'binary_crossentropy',\n",
    "                    'output3': 'binary_crossentropy', 'output4': 'binary_crossentropy'},\n",
    "              metrics={'output1': 'accuracy', 'output2': 'accuracy',\n",
    "                       'output3': 'accuracy', 'output4': 'accuracy'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_mbti_model_mlp(model, train_inputs, test_inputs):\n",
    "        X_train, y1_train, y2_train, y3_train, y4_train = train_inputs\n",
    "        X_test, y1_test, y2_test, y3_test, y4_test = test_inputs\n",
    "\n",
    "        model.fit(x=X_train,\n",
    "                y={'output1': y1_train, 'output2': y2_train, 'output3': y3_train, 'output4': y4_train},\n",
    "                epochs=3,\n",
    "                batch_size=64)\n",
    "        test_scores = model.evaluate(x=X_test,\n",
    "                                y={'output1': y1_test, 'output2': y2_test, 'output3': y3_test, 'output4': y4_test},\n",
    "                                verbose=1)\n",
    "        \n",
    "        y1_predict, y2_predict, y3_predict, y4_predict = model.predict(X_test)\n",
    "        y_predict_all = (y1_predict, y2_predict, y3_predict, y4_predict)\n",
    "    \n",
    "        print(f'Test Scores: {test_scores}')\n",
    "        return y_predict_all, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "109/109 [==============================] - 53s 473ms/step - loss: 1.9930 - output1_loss: 0.4964 - output2_loss: 0.3655 - output3_loss: 0.5016 - output4_loss: 0.6296 - output1_accuracy: 0.7739 - output2_accuracy: 0.8630 - output3_accuracy: 0.7490 - output4_accuracy: 0.6421\n",
      "Epoch 2/3\n",
      "109/109 [==============================] - 49s 452ms/step - loss: 0.6054 - output1_loss: 0.1551 - output2_loss: 0.1004 - output3_loss: 0.1073 - output4_loss: 0.2426 - output1_accuracy: 0.9398 - output2_accuracy: 0.9559 - output3_accuracy: 0.9653 - output4_accuracy: 0.9071\n",
      "Epoch 3/3\n",
      "109/109 [==============================] - 50s 455ms/step - loss: 0.0662 - output1_loss: 0.0195 - output2_loss: 0.0119 - output3_loss: 0.0081 - output4_loss: 0.0266 - output1_accuracy: 0.9939 - output2_accuracy: 0.9968 - output3_accuracy: 0.9984 - output4_accuracy: 0.9945\n",
      "55/55 [==============================] - 6s 108ms/step - loss: 3.0574 - output1_loss: 0.7825 - output2_loss: 0.5729 - output3_loss: 0.7234 - output4_loss: 0.9786 - output1_accuracy: 0.8409 - output2_accuracy: 0.8784 - output3_accuracy: 0.8259 - output4_accuracy: 0.7274\n",
      "55/55 [==============================] - 6s 113ms/step\n",
      "Test Scores: [3.0573952198028564, 0.7825258374214172, 0.5729391574859619, 0.723351001739502, 0.978579580783844, 0.8409221768379211, 0.8783861398696899, 0.8259366154670715, 0.7273775339126587]\n"
     ]
    }
   ],
   "source": [
    "y_predict_all, results = train_mbti_model_mlp(mlp_model, train_inputs, test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8409221768379211, 0.8783861398696899, 0.8259366154670715, 0.7273775339126587)\n",
      "Average Accuracy: 0.8181556165218353\n"
     ]
    }
   ],
   "source": [
    "loss_total = results[0]\n",
    "loss_output1, acc_output1 = results[1], results[5]\n",
    "loss_output2, acc_output2 = results[2], results[6]\n",
    "loss_output3, acc_output3 = results[3], results[7]\n",
    "loss_output4, acc_output4 = results[4], results[8]\n",
    "average_accuracy = (acc_output1 + acc_output2 + acc_output3 + acc_output4) / 4\n",
    "print((acc_output1, acc_output2, acc_output3, acc_output4))\n",
    "print(f'Average Accuracy: {average_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "    # Check if all four predicted classes match the true classes\n",
    "    correct_predictions = np.all(y_true == y_pred, axis=1)\n",
    "    accuracy = np.mean(correct_predictions)\n",
    "    return accuracy\n",
    "\n",
    "def threshold_prediction(value, threshold):\n",
    "    if value >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "y1_predict, y2_predict, y3_predict, y4_predict = y_predict_all\n",
    "threshold = 0.5\n",
    "y1_predict_thresholded = np.array([threshold_prediction(value, threshold) for value in y1_predict])\n",
    "y2_predict_thresholded = np.array([threshold_prediction(value, threshold) for value in y2_predict])\n",
    "y3_predict_thresholded = np.array([threshold_prediction(value, threshold) for value in y3_predict])\n",
    "y4_predict_thresholded = np.array([threshold_prediction(value, threshold) for value in y4_predict])\n",
    "\n",
    "y1_test_reshaped, y2_test_reshaped, y3_test_reshaped, y4_test_reshaped = y1_test.reshape(-1, 1), y2_test.reshape(-1, 1), y3_test.reshape(-1, 1), y4_test.reshape(-1, 1)\n",
    "\n",
    "y_pred_combined = np.vstack((y1_predict_thresholded,\n",
    "                                 y2_predict_thresholded,\n",
    "                                 y3_predict_thresholded,\n",
    "                                 y4_predict_thresholded)).T\n",
    "\n",
    "y_test_combined = np.vstack((y1_test_reshaped.T,\n",
    "                                y2_test_reshaped.T,\n",
    "                                y3_test_reshaped.T,\n",
    "                                y4_test_reshaped.T)).T\n",
    "\n",
    "accuracy = calculate_accuracy(y_test_combined, y_pred_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy across all four categories: 0.47780979827089337\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy across all four categories: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:53:34) [Clang 16.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95a8b902d17fe767a9a89dc40947dbbffb75fb8c37a8f89f9453213a57fd418c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
