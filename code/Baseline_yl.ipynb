{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample Data\n",
    "data = {\n",
    "    \"Sentence\": [\n",
    "        \"I love meeting new people and enjoy lively discussions.\",\n",
    "        \"I prefer written communication and need time alone to recharge.\",\n",
    "        \"I trust facts and data more than feelings.\",\n",
    "        \"I often think about the future and imagine the possibilities.\",\n",
    "        \"I make decisions based on my values and how it affects others.\",\n",
    "        \"I am very organized and like to plan things in advance.\",\n",
    "        \"I enjoy exploring details and practical applications.\",\n",
    "        \"I like to keep my options open and enjoy spontaneity.\"\n",
    "    ],\n",
    "    \"E_I\": [\"E\", \"I\", \"I\", \"I\", \"E\", \"I\", \"E\", \"E\"],  # Adjusted for actual binary classification\n",
    "    \"S_N\": [\"S\", \"N\", \"S\", \"N\", \"S\", \"N\", \"S\", \"N\"],  # Adjusted for actual binary classification\n",
    "    \"T_F\": [\"T\", \"F\", \"T\", \"F\", \"T\", \"F\", \"T\", \"F\"],  # Adjusted for actual binary classification\n",
    "    \"J_P\": [\"J\", \"P\", \"J\", \"P\", \"J\", \"P\", \"J\", \"P\"]   # Adjusted for actual binary classification\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocessing\n",
    "vocab_size = 1000\n",
    "embedding_dim = 32\n",
    "max_length = 20\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(df['Sentence'])\n",
    "sequences = tokenizer.texts_to_sequences(df['Sentence'])\n",
    "padded = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "E_I_labels = label_encoder.fit_transform(df['E_I'])\n",
    "S_N_labels = label_encoder.fit_transform(df['S_N'])\n",
    "T_F_labels = label_encoder.fit_transform(df['T_F'])\n",
    "J_P_labels = label_encoder.fit_transform(df['J_P'])\n",
    "\n",
    "# Combine the labels\n",
    "labels = np.vstack((E_I_labels, S_N_labels, T_F_labels, J_P_labels)).T\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Compile with a possibly different learning rate\u001b[39;00m\n\u001b[1;32m     18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccuracy\u001b[49m()])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'accuracy'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we produce our baseline model based on the structure of the CNN approach in the paper.\n",
    "Multilabel classification was used: 4 binary classifiers. \n",
    "Output layer consisted of 4 neurons with a sigmoid activation function. \n",
    "1D convolution of word embeddings were created and fed as input to the neural network. \n",
    "The neural network consisted of a max pooling layer and a dense layer, a sigmoid layer for obtaining multilabel classification results of the 4 binary classifiers.\n",
    "\"\"\"\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    Conv1D(256, 3, activation='relu'),  # Smaller filter and fewer filters\n",
    "    MaxPooling1D(3),  # Increased pooling size\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(16, activation='relu'),  # Reduced number of neurons\n",
    "    Dense(4, activation='sigmoid')  # Output layer for four binary classifications\n",
    "])\n",
    "\n",
    "# Compile with a possibly different learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.6930 - auc_2: 0.5694 - val_loss: 0.6989 - val_auc_2: 0.2500\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6865 - auc_2: 0.7604 - val_loss: 0.7058 - val_auc_2: 0.1875\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6822 - auc_2: 0.8090 - val_loss: 0.7107 - val_auc_2: 0.0625\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6768 - auc_2: 0.8819 - val_loss: 0.7142 - val_auc_2: 0.0625\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6711 - auc_2: 0.8715 - val_loss: 0.7179 - val_auc_2: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6656 - auc_2: 0.8889 - val_loss: 0.7224 - val_auc_2: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6604 - auc_2: 0.9028 - val_loss: 0.7279 - val_auc_2: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6545 - auc_2: 0.8889 - val_loss: 0.7342 - val_auc_2: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6479 - auc_2: 0.9236 - val_loss: 0.7410 - val_auc_2: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6416 - auc_2: 0.9306 - val_loss: 0.7478 - val_auc_2: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "# Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7478 - auc_2: 0.0000e+00\n",
      "Test loss 0.7478247880935669\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test loss\", test_loss)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('csci1470')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37ddd90401f1d77a01b8a047b2f4a1e6caea817e7c262c0d72d1b8dd241ceef0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
